import numpy as np
from skimage.measure import label, regionprops


def cal_totalarea(arr):
    arr = arr.astype('float32')
    arr[arr == 0] = np.nan
    total_num = np.count_nonzero(~np.isnan(arr))
    # 这里和fragstats里面的单位一致
    total_area = total_num * 30 * 30 * 0.0001
    return total_area

def cal_forestarea(arr):
    arr = arr.astype('float32')
    arr[arr == 0] = np.nan
    arr[arr != 2] = np.nan
    veg_num = np.count_nonzero(~np.isnan(arr))
    # 这里和fragstats里面的单位一致
    total_forest_area = veg_num * 30 * 30 * 0.0001
    return total_forest_area


def cal_ap(arr):
    arr = arr.astype('float32')
    arr[arr == 0] = np.nan
    total_num = np.count_nonzero(~np.isnan(arr))

    arr[arr != 2] = np.nan
    veg_num = np.count_nonzero(~np.isnan(arr))
    # 转换单位为公顷
    # total_area = area_num * 30 * 30 * 0.0001
    return -999.00 if total_num == 0 else float(veg_num*100 / total_num)

def cal_pd(arr):
    labeled_arr = label(arr == 2, connectivity=2)
    num_features = len(regionprops(labeled_arr))
    total_area = cal_totalarea(arr)
    return -999.00 if total_area == 0 else float(num_features * 100 / total_area)

def cal_ed(arr, target_value=2, neighbor_values=[1, 3, 4, 5, 6, 7, 8, 9]):
    total_area = cal_totalarea(arr)
    # 创建目标区域掩码
    target_mask = (arr == target_value)
    # 使用np.roll进行邻接操作，生成上、下、左、右的邻接矩阵
    up = np.roll(arr, shift=1, axis=0)  # 向上滚动
    down = np.roll(arr, shift=-1, axis=0)  # 向下滚动
    left = np.roll(arr, shift=1, axis=1)  # 向左滚动
    right = np.roll(arr, shift=-1, axis=1)  # 向右滚动
    # 设置边缘区域为背景值0，避免边界干扰
    up[0, :]=0
    down[-1, :]=0
    left[:, 0]=0
    right[:, -1]=0
    up[0, :] = down[-1, :] = left[:, 0] = right[:, -1] = 0
    # 计算每个目标像素与其邻接的邻居是否属于目标邻居值集合
    shared_up = (target_mask) & (np.isin(up, neighbor_values))
    shared_down = (target_mask) & (np.isin(down, neighbor_values))
    shared_left = (target_mask) & (np.isin(left, neighbor_values))
    shared_right = (target_mask) & (np.isin(right, neighbor_values))
    shared_edges_count = np.sum(shared_up) + np.sum(shared_down) + np.sum(shared_left) + np.sum(shared_right)
    return -999.00 if total_area == 0 else float(shared_edges_count*30 / total_area)


def cal_mpa(arr):
    forest_area=cal_forestarea(arr)
    labeled_arr = label(arr == 2, connectivity=2)
    num_features = len(regionprops(labeled_arr))
    return -999.00 if forest_area == 0 else float(forest_area/num_features)

def remove_ano(data,maxdata_sy,time_point_num):
    begin_sy = maxdata_sy - time_point_num
    begin_arr = data[:begin_sy]
    if begin_sy < 0:
        begin_arr = np.array([])

    # 末尾索引
    end_sy = maxdata_sy + time_point_num+1
    end_arr = data[end_sy:]
    if end_sy > len(data):
        end_arr = np.array([])
    # 对数据进行判断，如果新的数据为空，则退出循环
    data = np.append(begin_arr, end_arr)
    return data

def cal_relience(data):
    # 异常判断
    if np.isnan(data).any() or np.all(data == data[0]):
        return -999.00, -999.00, -999.00
    # 初始化, 异常发生的次数,每一次恢复力的叠加,
    num = 0
    sum_resilience = []
    time = []

    # 1.原始数据的滑动平均值用以避免出现云干扰,可以适当调整size大小,查看结果是否出现差异
    moving_mean_data = generic_filter(data, calmean, size=3, mode='nearest')

    while True:
        # 2. 识别小于阈值的异常事件(如果发现没有异常事件,则无法测定实际恢复力和恢复时间,返回-999,num返回0)
        outliers_values = data[data < -1]
        if outliers_values.size == 0:
            if num == 0:
                return -999.00, -999.00, num
            else:
                mean_re,mean_time = remove_outliers(sum_resilience,time)
                return mean_re,mean_time,num/37.00

        # 3. 识别异常事件中最大异常事件对应的异常值和索引(如果发现负最大异常值出现了多次,判定为数据错误,因此予以返回)
        maxdata = np.min(outliers_values)
        maxdata_sy = np.where(data == maxdata)[0][0]

        # 4. 计算最大异常时间对应的恢复力,和恢复时间
        t = 0
        check_sy = maxdata_sy
        while moving_mean_data[check_sy] < 0:
            check_sy = check_sy + 1
            t = t + 1
            if check_sy==len(moving_mean_data):
                break
        # t = np.argmax(data[maxdata_sy:] >= 0)-1
        if t == 0 or check_sy==len(moving_mean_data):
            data = remove_ano(data, maxdata_sy, 11)
            moving_mean_data = remove_ano(moving_mean_data, maxdata_sy, 11)
        else:
            num = num + 1
            time.append(t)
            sum_resilience.append(abs(maxdata) / t)
            # 5.移除本次最大异常事件的前后180天,避免单次事件对结果的干扰,并进行下一次测算
            data = remove_ano(data,maxdata_sy,11)
            moving_mean_data = remove_ano(moving_mean_data,maxdata_sy,11)
